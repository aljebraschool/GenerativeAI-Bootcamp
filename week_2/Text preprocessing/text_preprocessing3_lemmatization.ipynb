{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e00a68",
   "metadata": {},
   "source": [
    "## Text Preprocessing for Machine Learning - Lemmatization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf27449e",
   "metadata": {},
   "source": [
    "Lemmatization is the automated process of reducing a word to its base, \n",
    "\n",
    "dictionary form (known as a \"lemma\") by using vocabulary and morphological analysis.\n",
    "\n",
    "The goal is to remove inflections and return a valid word that you would find in a dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d620e64",
   "metadata": {},
   "source": [
    "Simple Analogy:\n",
    "    Think of a linguist carefully looking up a word in a dictionary to find its canonical entry. They use grammar rules and meaning to find the standard form.\n",
    "\n",
    "Key Point:\n",
    "    Lemmatization is a more intelligent and accurate method than stemming. It requires understanding the word's part of speech (like verb, noun) and returns a real word.\n",
    "\n",
    "Examples:\n",
    "\n",
    "- running → run (verb)\n",
    "\n",
    "- happily → happy (adjective)\n",
    "\n",
    "- better → good (adjective)\n",
    "\n",
    "- was → be (verb)\n",
    "\n",
    "- mice → mouse (noun)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee172cd",
   "metadata": {},
   "source": [
    "Why it's used:\n",
    "\n",
    "Its purpose is the same as stemming (to group word variations), but it's used when accuracy is critical. \n",
    "\n",
    "It's essential for advanced text analysis, language understanding, and generating human-readable output, as it doesn't produce gibberish stems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5329690a",
   "metadata": {},
   "source": [
    "## Lemmatization code Implementation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558c507a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/aljebra/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd845d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f5cfd0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('going', pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6f2c3b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('going', pos = 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb93bbcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "326b6358",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"eats\", 'eaten', 'eating', 'writes', 'wrote', 'writen', 'go', 'goes', 'going', 'programming', 'program', 'history', 'finally', 'final', 'congratulate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1823bcdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eats ----> eats\n",
      "eaten ----> eaten\n",
      "eating ----> eating\n",
      "writes ----> writes\n",
      "wrote ----> wrote\n",
      "writen ----> writen\n",
      "go ----> go\n",
      "goes ----> go\n",
      "going ----> going\n",
      "programming ----> programming\n",
      "program ----> program\n",
      "history ----> history\n",
      "finally ----> finally\n",
      "final ----> final\n",
      "congratulate ----> congratulate\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word + \" ----> \" + lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "126a8e55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eats ----> eat\n",
      "eaten ----> eat\n",
      "eating ----> eat\n",
      "writes ----> write\n",
      "wrote ----> write\n",
      "writen ----> writen\n",
      "go ----> go\n",
      "goes ----> go\n",
      "going ----> go\n",
      "programming ----> program\n",
      "program ----> program\n",
      "history ----> history\n",
      "finally ----> finally\n",
      "final ----> final\n",
      "congratulate ----> congratulate\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "POS - Part of speech tag\n",
    "Verb - v\n",
    "None - n\n",
    "Adjective - a\n",
    "Adverb = r\n",
    "'''\n",
    "\n",
    "for word in words:\n",
    "    print(word + \" ----> \" + lemmatizer.lemmatize(word, pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d17aaae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fairly'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('fairly', pos = 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67d54d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'sportingly'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('sportingly', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0cca39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
